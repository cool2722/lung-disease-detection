{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chest X-Ray Classification using U-Net with and without Attention Mechanism\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_path = 'dataset\\train'\n",
    "image_paths = []\n",
    "categories = []\n",
    "categories_list = ['Lung Tumour', 'Normal', 'Pneumonia', 'Tuberculosis', 'COPD', 'Other diseases']\n",
    "\n",
    "for category in categories_list:\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    if os.path.exists(category_path):\n",
    "        for image_name in os.listdir(category_path):\n",
    "            image_path = os.path.join(category_path, image_name)\n",
    "            image_paths.append(image_path)\n",
    "            categories.append(category)\n",
    "\n",
    "df = pd.DataFrame({'image_path': image_paths, 'category': categories})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "category_counts = df['category'].value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Count of Images per Category\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"viridis\", len(category_counts)))\n",
    "plt.title(\"Proportion of Images per Category\")\n",
    "plt.show()\n",
    "\n",
    "num_images_per_category = 5\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, category in enumerate(df['category'].unique()):\n",
    "    category_images = df[df['category'] == category]['image_path']\n",
    "    selected_images = random.sample(list(category_images), num_images_per_category)\n",
    "    for j, image_path in enumerate(selected_images):\n",
    "        img = Image.open(image_path)\n",
    "        plt.subplot(len(df['category'].unique()), num_images_per_category, i * num_images_per_category + j + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(category if j == 0 else \"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "df = df[['image_path', 'category_encoded']]\n",
    "\n",
    "# Oversample data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(df[['image_path']], df['category_encoded'])\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=['image_path'])\n",
    "df_resampled['category_encoded'] = y_resampled\n",
    "\n",
    "# Split data\n",
    "train_df_new, temp_df_new = train_test_split(df_resampled, train_size=0.8, shuffle=True, random_state=42, stratify=df_resampled['category_encoded'])\n",
    "valid_df_new, test_df_new = train_test_split(temp_df_new, test_size=0.5, shuffle=True, random_state=42, stratify=temp_df_new['category_encoded'])\n",
    "\n",
    "# Data generators\n",
    "batch_size = 16\n",
    "img_size = (256, 256)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "tr_gen = ImageDataGenerator(rescale=1./255)\n",
    "ts_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen_new = tr_gen.flow_from_dataframe(train_df_new, x_col='image_path', y_col='category_encoded', target_size=img_size, class_mode='sparse', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "valid_gen_new = ts_gen.flow_from_dataframe(valid_df_new, x_col='image_path', y_col='category_encoded', target_size=img_size, class_mode='sparse', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "test_gen_new = ts_gen.flow_from_dataframe(test_df_new, x_col='image_path', y_col='category_encoded', target_size=img_size, class_mode='sparse', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# Check GPU availability\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define U-Net model\n",
    "def unet_classification_model(input_size=(256, 256, 3), num_classes=4):\n",
    "    inputs = layers.Input(input_size)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
    "    bottleneck = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    bottleneck = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(bottleneck)\n",
    "    upconv3 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bottleneck)\n",
    "    concat3 = layers.concatenate([upconv3, conv3])\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(concat3)\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    upconv2 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4)\n",
    "    concat2 = layers.concatenate([upconv2, conv2])\n",
    "    conv5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(concat2)\n",
    "    conv5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    upconv1 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    concat1 = layers.concatenate([upconv1, conv1])\n",
    "    conv6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(concat1)\n",
    "    conv6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    gap = layers.GlobalAveragePooling2D()(conv6)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(gap)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "model = unet_classification_model(input_size=(256, 256, 3), num_classes=4)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_gen_new, epochs=5, batch_size=16, validation_data=valid_gen_new, steps_per_epoch=train_gen_new.samples // train_gen_new.batch_size, validation_steps=valid_gen_new.samples // valid_gen_new.batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define U-Net with attention model\n",
    "def attention_gate(x, g, inter_channels):\n",
    "    theta_x = layers.Conv2D(inter_channels, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    phi_g = layers.Conv2D(inter_channels, (1, 1), strides=(1, 1), padding='same')(g)\n",
    "    add_xg = layers.Add()([theta_x, phi_g])\n",
    "    relu_xg = layers.Activation('relu')(add_xg)\n",
    "    psi = layers.Conv2D(1, (1, 1), strides=(1, 1), padding='same')(relu_xg)\n",
    "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
    "    attention = layers.Multiply()([x, sigmoid_xg])\n",
    "    return attention\n",
    "\n",
    "def unet_with_attention(input_size=(256, 256, 3), num_classes=4):\n",
    "    inputs = layers.Input(input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen_new, \n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    validation_data=valid_gen_new, \n",
    "    steps_per_epoch=train_gen_new.samples // train_gen_new.batch_size,\n",
    "    validation_steps=valid_gen_new.samples // valid_gen_new.batch_size,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model.predict(test_gen_new)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = test_gen_new.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_gen_new.class_indices.keys(), yticklabels=test_gen_new.class_indices.keys())\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=test_gen_new.class_indices.keys())\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
