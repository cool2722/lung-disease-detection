{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 185597952 bytes (1639501952 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/xhlulu/vinbigdata-chest-xray-png-512px-original-ratio?dataset_version_number=1 (185597952/1825099904) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.70G/1.70G [01:47<00:00, 15.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\jsayed\\.cache\\kagglehub\\datasets\\xhlulu\\vinbigdata-chest-xray-png-512px-original-ratio\\versions\\1\n",
      "len of path: 106\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"xhlulu/vinbigdata-chest-xray-png-512px-original-ratio\")\n",
    "#path = kagglehub.dataset_download(\"xhlulu/vinbigdata-chest-xray-resized-png-256x256\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n",
      "None\n",
      "None\n",
      "CUDA Available: False\n",
      "Device Count: 0\n",
      "GPU Name: No GPU detected\n",
      "Current Device: No GPU detected\n",
      "Using device: cpu\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device Count:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "print(\"Current Device:\", torch.cuda.current_device() if torch.cuda.is_available() else \"No GPU detected\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print()\n",
    "print()\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsayed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jsayed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\jsayed/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:08<00:00, 5.25MB/s]\n",
      "C:\\Users\\jsayed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\jsayed/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:12<00:00, 6.73MB/s]\n",
      "C:\\Users\\jsayed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\jsayed/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:11<00:00, 9.07MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet models\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Remove classification head (fully connected layer)\n",
    "for model in [resnet18, resnet34, resnet50]:\n",
    "    model.fc = nn.Identity()  # Output raw features instead of class scores\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Move models to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "resnet18, resnet34, resnet50 = resnet18.to(device), resnet34.to(device), resnet50.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(models, image):\n",
    "    with torch.no_grad():  # Disable gradients for efficiency\n",
    "        features = [model(image).flatten(start_dim=1) for model in models]  # Extract feature vectors\n",
    "        return torch.cat(features, dim=1)  # Concatenate all feature vectors\n",
    "\n",
    "meta_learner = nn.Linear(512 + 512 + 2048, 2).to(device)  # 2 output classes (e.g., normal vs disease)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See X num of files from train set for labelling purpose and send labels to new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset with 4424 entries saved to C:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-detection\\dataset\\filtered_train_1000.csv\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "X = 100  # Number of files to extract\n",
    "train_folder = r\"C:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-detection\\dataset\\train\"  # Path to your train dataset folder\n",
    "csv_file = r\"C:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-detection\\dataset\\train.csv\"  # Path to your full train.csv file\n",
    "output_csv = rf\"C:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-detection\\dataset\\filtered_train_{X}.csv\"  # Output CSV file\n",
    "\n",
    "# STEP 1: Get the first X UNIQUE filenames from the dataset folder\n",
    "all_files = sorted(os.listdir(train_folder))  # Sort for consistency\n",
    "\n",
    "# Extract unique filenames (remove extensions like .dicom)\n",
    "unique_files = set()\n",
    "selected_files = []\n",
    "\n",
    "for file in all_files:\n",
    "    file_base = os.path.splitext(file)[0]  # Remove extension\n",
    "    if file_base not in unique_files:  # Ensure uniqueness\n",
    "        unique_files.add(file_base)\n",
    "        selected_files.append(file_base)\n",
    "    if len(selected_files) == X:  # Stop when we reach X unique files\n",
    "        break\n",
    "\n",
    "# STEP 2: Load the train.csv file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# STEP 3: Filter the CSV file to only include selected filenames\n",
    "filtered_df = df[df['image_id'].isin(selected_files)]  # Assuming 'filename' is the column name\n",
    "\n",
    "# STEP 4: Save the filtered CSV\n",
    "filtered_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Filtered dataset with {len(filtered_df)} entries saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungXrayDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file with image filenames & labels.\n",
    "            img_dir (str): Path to the folder containing images.\n",
    "            transform (callable, optional): Optional transform to be applied.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get filename and label\n",
    "        img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0])  # Column 0 = filename\n",
    "        label = int(self.data.iloc[idx, 1])  # Column 1 = label\n",
    "\n",
    "        # Open image\n",
    "        image = Image.open(img_name).convert(\"RGB\")  # Ensure it's in RGB format\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label  # Return the image tensor and label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 67914 images\n"
     ]
    }
   ],
   "source": [
    "# Define Image Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1,1] range\n",
    "])\n",
    "\n",
    "\n",
    "# Paths\n",
    "csv_path = csv_file  # CSV file with labels\n",
    "img_folder = train_folder  # Folder where images are stored\n",
    "\n",
    "# Create dataset\n",
    "dataset = LungXrayDataset(csv_path, img_folder, transform=transform)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Check dataset size\n",
    "print(f\"Dataset contains {len(dataset)} images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of images & labels\n",
    "images, labels = next(iter(dataloader))\n",
    "\n",
    "# Check tensor shapes\n",
    "print(f\"Image batch shape: {images.shape}\")  # Should be (batch_size, 3, 224, 224)\n",
    "print(f\"Labels batch shape: {labels.shape}\")  # Should be (batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(meta_learner.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(5):  # Train for 5 epochs\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Step 1: Extract features from ResNet models\n",
    "        features = extract_features([resnet18, resnet34, resnet50], images)\n",
    "\n",
    "        # Step 2: Pass features through the meta-learner\n",
    "        outputs = meta_learner(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Step 3: Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/5], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Prepare image\n",
    "    features = extract_features([resnet18, resnet34, resnet50], image)  # Get features\n",
    "    output = meta_learner(features)  # Predict\n",
    "    return torch.argmax(output, dim=1).item()  # Return class label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
